{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import ast\n",
    "import re\n",
    "from utils import helpers as hpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading OpenStack changes...\n",
      "OpenStack changes loaded successfully...\n"
     ]
    }
   ],
   "source": [
    "df = hpr.combine_openstack_data(changes_path=\"/Changes3/\")\n",
    "# df = df[df['status']!='NEW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional metadata through merges\n",
    "# df2 = pd.merge(\n",
    "#     left=df2,\n",
    "#     right=df[[\"number\", \"is_owner_bot\", \"status\"]],\n",
    "#     left_on=['Source'],\n",
    "#     right_on=['number'],\n",
    "#     how='left',\n",
    "#     suffixes=('_target', '_source')\n",
    "# )\n",
    "\n",
    "# df2 = pd.merge(\n",
    "#     left=df2,\n",
    "#     right=df[[\"number\", \"is_owner_bot\", \"status\"]],\n",
    "#     left_on=['Target'],\n",
    "#     right_on=['number'],\n",
    "#     how='left',\n",
    "#     suffixes=('_source', '_target')\n",
    "# )\n",
    "df3.drop(columns=[\"number_source\", \"number_target\"], inplace=True)\n",
    "df3 = pd.merge(\n",
    "    left=df3,\n",
    "    right=df[[\"number\", \"is_owner_bot\"]],\n",
    "    left_on=['Source'],\n",
    "    right_on=['number'],\n",
    "    how='left',\n",
    "    suffixes=('_target', '_source')\n",
    ")\n",
    "\n",
    "df3 = pd.merge(\n",
    "    left=df3,\n",
    "    right=df[[\"number\", \"is_owner_bot\"]],\n",
    "    left_on=['Target'],\n",
    "    right_on=['number'],\n",
    "    how='left',\n",
    "    suffixes=('_source', '_target')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[(df2[\"is_owner_bot_source\"]==0)&(df2[\"is_owner_bot_target\"]==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[(df2[\"status_source\"]!=\"NEW\")&(df2[\"status_source\"]!=\"NEW\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49181"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(hpr.flatten_list(df2[['Source', 'Target']].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2[\"Source\"]!=df2[\"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48854"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df3[(df3[\"is_owner_bot_source\"]==0)&(df3[\"is_owner_bot_target\"]==0)]\n",
    "df3 = df3[(df3[\"Source_status\"]!=\"NEW\")&(df3[\"Target_status\"]!=\"NEW\")]\n",
    "len(set(hpr.flatten_list(df3[['Source', 'Target']].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['messages'] = df.loc[df['messages'].notna(), 'messages'].map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = df['created'].map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The median of changes per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'creation_date' to string format 'year-month-day'\n",
    "df['created_str'] = df['created'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Group by 'creation_date' and count the number of rows per day\n",
    "daily_counts = df.groupby(df['created'].dt.date).size()\n",
    "\n",
    "# Display the result\n",
    "daily_counts_df = daily_counts.reset_index(name='count')\n",
    "daily_counts_df.columns = ['created_str', 'count']\n",
    "\n",
    "daily_counts_df['count'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_build_fialure = pd.read_csv(osp.join(\".\", \"Files\", \"Metrics\", \"num_build_failures.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The growth of dependent changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep_ned_cha = pd.read_csv(osp.join('Files', 'source_target_evolution.csv'))\n",
    "deps_need_changes = df_dep_ned_cha['Source'].tolist() + df_dep_ned_cha['Target'].tolist()\n",
    "df['Count'] = 0\n",
    "df_reduced = df.loc[df['number'].isin(deps_need_changes), ['status', 'created', 'Count']]\n",
    "\n",
    "df_reduced['Year'] = df_reduced['created'].map(lambda x: x.year)\n",
    "\n",
    "# df_reduced = df_reduced.groupby('Year').count().reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_reduced[df_reduced['status']=='MERGED']\n",
    "df_merged = df_merged.groupby('Year').count().reset_index(level=0)\n",
    "df_merged['Status'] = 'MERGED'\n",
    "\n",
    "df_abandoned = df_reduced[df_reduced['status']=='ABANDONED']\n",
    "df_abandoned = df_abandoned.groupby('Year').count().reset_index(level=0)\n",
    "df_abandoned['Status'] = 'ABANDONED'\n",
    "\n",
    "df_new = df_reduced[df_reduced['status']=='NEW']\n",
    "df_new = df_new.groupby('Year').count().reset_index(level=0)\n",
    "df_new['Status'] = 'NEW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = pd.concat((df_merged[['Year', 'Status', 'Count']], df_abandoned[['Year', 'Status', 'Count']], df_new[['Year', 'Status', 'Count']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perc_dependencies(row):\n",
    "    all_changes = df.loc[(df['status']==row['Status'])&(df['Year'] == row['Year']), 'number'].nunique()\n",
    "    return round(100 * (row['Count'] / all_changes), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced['percentage'] = df_reduced.apply(calc_perc_dependencies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced.to_csv(\"./Files/Preliminary/deps_evolution2.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When dependent changes are identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:22: SyntaxWarning: invalid escape sequence '\\:'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:22: SyntaxWarning: invalid escape sequence '\\:'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/p4/wn9d12jj6g78td0tl7gx7xlw0000gp/T/ipykernel_90679/1224035538.py:14: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  rs = re.findall(\"%s:\\s[a-zA-Z0-9/\\.\\:\\+\\-\\#]{6,}\" % (attr), x)\n",
      "/var/folders/p4/wn9d12jj6g78td0tl7gx7xlw0000gp/T/ipykernel_90679/1224035538.py:22: SyntaxWarning: invalid escape sequence '\\:'\n",
      "  number_pattern = re.search(\"#?https?[\\:][/]{2}review[\\.](opendev|openstack)[\\.]org([a-z0-9A-Z\\-\\+/\\.#]*)\\d+\", row)\n",
      "/var/folders/p4/wn9d12jj6g78td0tl7gx7xlw0000gp/T/ipykernel_90679/1224035538.py:24: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  result.append(int(re.search(\"\\d+$\", number_pattern[0][0:])[0]))\n"
     ]
    }
   ],
   "source": [
    "def time_diff(start, end):\n",
    "    if start > end:\n",
    "        start, end = end, start\n",
    "    current_date =  datetime.strptime(end, \"%Y-%m-%d %H:%M:%S\") \n",
    "    previous_date = datetime.strptime(start, \"%Y-%m-%d %H:%M:%S\") \n",
    "    diff = current_date - previous_date\n",
    "    diff = float(\"{:.2f}\".format(diff.total_seconds() / 3600))\n",
    "    return diff\n",
    "\n",
    "\n",
    "def extract_attr(x, attr):\n",
    "    '''Extracts the passed-on parameter values out of the commit message \n",
    "    '''\n",
    "    rs = re.findall(\"%s:\\s[a-zA-Z0-9/\\.\\:\\+\\-\\#]{6,}\" % (attr), x)\n",
    "    result = []\n",
    "    for row in rs:\n",
    "        row = row[len(attr) + 2:]\n",
    "        change_id_pattern = re.search(r\"[a-zA-Z0-9]{41}\", row)\n",
    "        if change_id_pattern:\n",
    "            result.append(change_id_pattern[0])\n",
    "            continue\n",
    "        number_pattern = re.search(\"#?https?[\\:][/]{2}review[\\.](opendev|openstack)[\\.]org([a-z0-9A-Z\\-\\+/\\.#]*)\\d+\", row)\n",
    "        if number_pattern:\n",
    "            result.append(int(re.search(\"\\d+$\", number_pattern[0][0:])[0]))\n",
    "    return result if len(result) != 0 else None\n",
    "\n",
    "\n",
    "def retrieve_revision_date(row, attr, return_revision_date=True):\n",
    "    number = None\n",
    "    second_number = None\n",
    "\n",
    "    if attr == \"Depends-On\":\n",
    "        number = row[\"Target\"]\n",
    "        second_number = row[\"Source\"]\n",
    "        change_id = row[\"Source_change_id\"]\n",
    "    else:\n",
    "        number = row[\"Source\"]\n",
    "        second_number = row[\"Target\"]\n",
    "        change_id = row[\"Target_change_id\"]\n",
    "\n",
    "    df_row = df.loc[df[\"number\"] == number]\n",
    "    revisions = ast.literal_eval(df_row[\"revisions\"].values[0])\n",
    "    revisions = sorted(revisions, key=lambda x: x[\"created\"])\n",
    "    if  len(revisions) == 1:\n",
    "        if return_revision_date:\n",
    "            return revisions[0][\"created\"][:-11]\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    first_revision = revisions[0]\n",
    "    first_message = first_revision[\"message\"]\n",
    "\n",
    "    results = extract_attr(first_message, attr)\n",
    "\n",
    "    if results and ((change_id in results) or (second_number in results)):\n",
    "        if return_revision_date:\n",
    "            return first_revision[\"created\"][:-11]\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    for i in range(1,len(revisions)):\n",
    "        current_message = revisions[i][\"message\"]\n",
    "        created = revisions[i][\"created\"]\n",
    "        results = extract_attr(current_message, attr)\n",
    "        \n",
    "        if results and ((change_id in results) or (second_number in results)):\n",
    "\n",
    "            if return_revision_date:\n",
    "                return created[:-11]\n",
    "            else:\n",
    "                return i + 1\n",
    "\n",
    "def is_same_developer(row):\n",
    "    return \"Same\" if row[\"Source_dev\"] == row[\"Target_dev\"] else \"Different\"\n",
    "\n",
    "def identify_dependency(row):\n",
    "    source_date = row[\"Source_date\"] \n",
    "    target_date = row[\"Target_date\"]\n",
    "    link_date = datetime.strptime(row[\"link_date\"], \"%Y-%m-%d %H:%M:%S\")\n",
    "    delta1 = (target_date - link_date).total_seconds() / (60 * 60)\n",
    "    delta2 = (source_date - link_date).total_seconds() / (60 * 60)\n",
    "\n",
    "    return abs(delta2)\n",
    "    # return min(abs(delta1), abs(delta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depends-On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_changes = df['number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p4/wn9d12jj6g78td0tl7gx7xlw0000gp/T/ipykernel_90679/1224035538.py:14: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  rs = re.findall(\"%s:\\s[a-zA-Z0-9/\\.\\:\\+\\-\\#]{6,}\" % (attr), x)\n",
      "/var/folders/p4/wn9d12jj6g78td0tl7gx7xlw0000gp/T/ipykernel_90679/1224035538.py:22: SyntaxWarning: invalid escape sequence '\\:'\n",
      "  number_pattern = re.search(\"#?https?[\\:][/]{2}review[\\.](opendev|openstack)[\\.]org([a-z0-9A-Z\\-\\+/\\.#]*)\\d+\", row)\n",
      "/var/folders/p4/wn9d12jj6g78td0tl7gx7xlw0000gp/T/ipykernel_90679/1224035538.py:24: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  result.append(int(re.search(\"\\d+$\", number_pattern[0][0:])[0]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 44\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# # Read the CSV file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# # df_depends_on = pd.read_csv(\"./Files/source_target_depends2.csv\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# # # Add is_cross column\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# df_depends_on[\"is_cross\"] = df_depends_on.apply(lambda row: \"Cross\" if row[\"Source_repo\"] != row[\"Target_repo\"] else \"Same\", axis=1)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m df_depends_on[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink_date\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_depends_on\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretrieve_revision_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDepends-On\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# # df_depends_on[\"worked_revisions\"] = df_depends_on.apply(retrieve_revision_date, args=(\"Depends-On\",False,), axis=1)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# # df_depends_on[\"same_dev\"] = df_depends_on.apply(is_same_developer, axis=1)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# # df_depends_on[\"when_identified\"] = df_depends_on[[\"Source_date\", \"Target_date\", \"link_date\"]].apply(identify_dependency, axis=1)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# # df_depends_on[\"deps_label\"] = \"Depends-On\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# # # df_depends_on = df_depends_on[(df_depends_on['Source_status']=='MERGED')|(df_depends_on['Target_status']=='MERGED')]\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[22], line 41\u001b[0m, in \u001b[0;36mretrieve_revision_date\u001b[0;34m(row, attr, return_revision_date)\u001b[0m\n\u001b[1;32m     38\u001b[0m     second_number \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     39\u001b[0m     change_id \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget_change_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 41\u001b[0m df_row \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumber\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m]\n\u001b[1;32m     42\u001b[0m revisions \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(df_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevisions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     43\u001b[0m revisions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(revisions, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Read the CSV file\n",
    "# # df_depends_on = pd.read_csv(\"./Files/source_target_depends2.csv\")\n",
    "\n",
    "# # # Filter rows where both Source and Target are in all_changes\n",
    "# # df_depends_on = df_depends_on[df_depends_on['Source'].isin(all_changes) & df_depends_on['Target'].isin(all_changes)]\n",
    "\n",
    "# # # Get Source fields using merge\n",
    "# df_depends_on = pd.merge(\n",
    "#     df_depends_on,\n",
    "#     df[[\"number\", \"status\", \"change_id\", \"is_owner_bot\", \"owner_account_id\", \"created\"]].rename(\n",
    "#         columns={\n",
    "#             \"number\": \"Source\",\n",
    "#             \"status\": \"Source_status\",\n",
    "#             \"change_id\": \"Source_change_id\",\n",
    "#             \"is_owner_bot\": \"is_source_bot\",\n",
    "#             \"owner_account_id\": \"Source_dev\",\n",
    "#             \"created\": \"Source_date\"\n",
    "#         }\n",
    "#     ),\n",
    "#     on=\"Source\",\n",
    "#     how=\"left\"\n",
    "# )\n",
    "\n",
    "# # Get Target fields using merge\n",
    "# df_depends_on = pd.merge(\n",
    "#     df_depends_on,\n",
    "#     df[[\"number\", \"status\", \"change_id\", \"revisions\", \"is_owner_bot\", \"owner_account_id\", \"created\"]].rename(\n",
    "#         columns={\n",
    "#             \"number\": \"Target\",\n",
    "#             \"status\": \"Target_status\",\n",
    "#             \"change_id\": \"Target_change_id\",\n",
    "#             \"is_owner_bot\": \"is_target_bot\",\n",
    "#             \"owner_account_id\": \"Target_dev\",\n",
    "#             \"created\": \"Target_date\"\n",
    "#         }\n",
    "#     ),\n",
    "#     on=\"Target\",\n",
    "#     how=\"left\"\n",
    "# )\n",
    "\n",
    "# # # Add is_cross column\n",
    "# df_depends_on[\"is_cross\"] = df_depends_on.apply(lambda row: \"Cross\" if row[\"Source_repo\"] != row[\"Target_repo\"] else \"Same\", axis=1)\n",
    "\n",
    "df_depends_on[\"link_date\"] = df_depends_on.apply(retrieve_revision_date, args=(\"Depends-On\",), axis=1)\n",
    "# # df_depends_on[\"worked_revisions\"] = df_depends_on.apply(retrieve_revision_date, args=(\"Depends-On\",False,), axis=1)\n",
    "# # df_depends_on[\"same_dev\"] = df_depends_on.apply(is_same_developer, axis=1)\n",
    "# # df_depends_on[\"when_identified\"] = df_depends_on[[\"Source_date\", \"Target_date\", \"link_date\"]].apply(identify_dependency, axis=1)\n",
    "# # df_depends_on[\"deps_label\"] = \"Depends-On\"\n",
    "\n",
    "# # # df_depends_on = df_depends_on[(df_depends_on['Source_status']=='MERGED')|(df_depends_on['Target_status']=='MERGED')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Needed-By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df_needed_by = pd.read_csv(\"./Files/source_target_needed2.csv\")\n",
    "\n",
    "# Filter rows where both Source and Target are in all_changes\n",
    "df_needed_by = df_needed_by[df_needed_by['Source'].isin(all_changes) & df_needed_by['Target'].isin(all_changes)]\n",
    "\n",
    "# Get Source fields using merge\n",
    "df_needed_by = pd.merge(\n",
    "    df_needed_by,\n",
    "    df[[\"number\", \"status\", \"change_id\", \"is_owner_bot\", \"owner_account_id\", \"created\"]].rename(\n",
    "        columns={\n",
    "            \"number\": \"Source\",\n",
    "            \"status\": \"Source_status\",\n",
    "            \"change_id\": \"Source_change_id\",\n",
    "            \"is_owner_bot\": \"is_source_bot\",\n",
    "            \"owner_account_id\": \"Source_dev\",\n",
    "            \"created\": \"Source_date\"\n",
    "        }\n",
    "    ),\n",
    "    on=\"Source\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Get Target fields using merge\n",
    "df_needed_by = pd.merge(\n",
    "    df_needed_by,\n",
    "    df[[\"number\", \"status\", \"change_id\", \"revisions\", \"is_owner_bot\", \"owner_account_id\", \"created\"]].rename(\n",
    "        columns={\n",
    "            \"number\": \"Target\",\n",
    "            \"status\": \"Target_status\",\n",
    "            \"change_id\": \"Target_change_id\",\n",
    "            \"is_owner_bot\": \"is_target_bot\",\n",
    "            \"owner_account_id\": \"Target_dev\",\n",
    "            \"created\": \"Target_date\"\n",
    "        }\n",
    "    ),\n",
    "    on=\"Target\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Add is_cross column\n",
    "df_needed_by[\"is_cross\"] = df_needed_by.apply(lambda row: \"Cross\" if row[\"Source_repo\"] != row[\"Target_repo\"] else \"Same\", axis=1)\n",
    "\n",
    "df_needed_by[\"link_date\"] = df_needed_by.apply(retrieve_revision_date, args=(\"Depends-On\",), axis=1)\n",
    "df_needed_by[\"worked_revisions\"] = df_needed_by.apply(retrieve_revision_date, args=(\"Depends-On\",False,), axis=1)\n",
    "df_needed_by[\"same_dev\"] = df_needed_by.apply(is_same_developer, axis=1)\n",
    "df_needed_by[\"when_identified\"] = df_needed_by[[\"Source_date\", \"Target_date\", \"link_date\"]].apply(identify_dependency, axis=1)\n",
    "df_needed_by[\"deps_label\"] = \"Needed-By\"\n",
    "\n",
    "# df_needed_by = df_needed_by[(df_needed_by['Source_status']=='MERGED')|(df_needed_by['Target_status']=='MERGED')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_identification = pd.concat((df_depends_on, df_needed_by)).sort_values(\"when_identified\")\n",
    "dependency_identification = dependency_identification.drop_duplicates(subset=[\"Source\", \"Target\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The frequency of changes that depends among each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deps = pd.read_csv(\"./Files/source_target_evolution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(set(df_deps[\"Source\"].tolist()).union(df_deps[\"Target\"].tolist()))\n",
    "# df_deps = df_deps[(df_deps['Source_status']!='NEW')&(df_deps['Target_status']!='NEW')]\n",
    "df_deps.drop(columns=[\"number_source\", \"number_target\"], inplace=True)\n",
    "df_deps = pd.merge(\n",
    "    left=df_deps,\n",
    "    right=df[[\"number\", \"change_id\"]],\n",
    "    left_on=['Source'],\n",
    "    right_on=['number'],\n",
    "    how='left',\n",
    "    suffixes=('_target', '_source')\n",
    ")\n",
    "df_deps = pd.merge(\n",
    "    left=df_deps,\n",
    "    right=df[[\"number\", \"change_id\"]],\n",
    "    left_on=['Target'],\n",
    "    right_on=['number'],\n",
    "    how='left',\n",
    "    suffixes=('_source', '_target')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deps = df_deps[(df_deps['Source_status']==\"MERGED\")|(df_deps['Target_status']==\"MERGED\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deps.drop_duplicates(subset=[\"change_id_source\", \"change_id_target\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Source_repo</th>\n",
       "      <th>Target_repo</th>\n",
       "      <th>Source_status</th>\n",
       "      <th>owner_account_id_source</th>\n",
       "      <th>Source_created</th>\n",
       "      <th>Target_status</th>\n",
       "      <th>owner_account_id_target</th>\n",
       "      <th>Target_created</th>\n",
       "      <th>number_source</th>\n",
       "      <th>change_id_source</th>\n",
       "      <th>number_target</th>\n",
       "      <th>change_id_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26005</td>\n",
       "      <td>26006</td>\n",
       "      <td>oslo-incubator</td>\n",
       "      <td>ceilometer</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-04-03 15:23:05</td>\n",
       "      <td>ABANDONED</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-04-03 15:23:50</td>\n",
       "      <td>26005.0</td>\n",
       "      <td>Ic01e0f16fe9e7634708fbb51499ccea3f4f40d63</td>\n",
       "      <td>26006.0</td>\n",
       "      <td>I2a3be7741e48b3b9fa5b0f182ddb25a0e46977ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66146</td>\n",
       "      <td>64831</td>\n",
       "      <td>pbr</td>\n",
       "      <td>requirements</td>\n",
       "      <td>ABANDONED</td>\n",
       "      <td>2750</td>\n",
       "      <td>2014-01-12 00:41:12</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>2750</td>\n",
       "      <td>2014-01-03 13:58:35</td>\n",
       "      <td>66146.0</td>\n",
       "      <td>I01b2b7c78e7e7144280c98cdbbe29b012a8a8d93</td>\n",
       "      <td>64831.0</td>\n",
       "      <td>I7a22dbb47e85f3adf5d43583f5b9bac4f65fde14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66453</td>\n",
       "      <td>71359</td>\n",
       "      <td>neutron</td>\n",
       "      <td>devstack</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>1923</td>\n",
       "      <td>2014-01-13 22:48:28</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>1923</td>\n",
       "      <td>2014-02-05 19:48:53</td>\n",
       "      <td>66453.0</td>\n",
       "      <td>I92619a95bca2ae0c37e7fdd39da30119b43d1ad6</td>\n",
       "      <td>71359.0</td>\n",
       "      <td>I0958457355036fdab93156cd7fb4afd1a458918b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153227</td>\n",
       "      <td>83150</td>\n",
       "      <td>project-config</td>\n",
       "      <td>oslo.messaging</td>\n",
       "      <td>ABANDONED</td>\n",
       "      <td>8415</td>\n",
       "      <td>2015-02-05 13:29:18</td>\n",
       "      <td>ABANDONED</td>\n",
       "      <td>6928</td>\n",
       "      <td>2014-03-26 18:01:12</td>\n",
       "      <td>153227.0</td>\n",
       "      <td>I893f9a1c259157bc6e6829fe34067ede365c15b7</td>\n",
       "      <td>83150.0</td>\n",
       "      <td>I9708322308655cbb4832fec1351ea1215e6e11ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178352</td>\n",
       "      <td>86978</td>\n",
       "      <td>project-config</td>\n",
       "      <td>grenade</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>6899</td>\n",
       "      <td>2015-04-28 19:24:44</td>\n",
       "      <td>ABANDONED</td>\n",
       "      <td>4328</td>\n",
       "      <td>2014-04-11 17:54:33</td>\n",
       "      <td>178352.0</td>\n",
       "      <td>I3e0f01221590f5e42f0c8fa659df62f83e0591af</td>\n",
       "      <td>86978.0</td>\n",
       "      <td>Id8f5875e1ae6a813808807571f511939ab4caf88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63225</th>\n",
       "      <td>903099</td>\n",
       "      <td>903095</td>\n",
       "      <td>requirements</td>\n",
       "      <td>cinder</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>13425</td>\n",
       "      <td>2023-12-07 18:02:36</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>13425</td>\n",
       "      <td>2023-12-07 16:47:22</td>\n",
       "      <td>903099.0</td>\n",
       "      <td>I9027eac8bd5bf1efc9ef619d578b2e0d9450027f</td>\n",
       "      <td>903095.0</td>\n",
       "      <td>I3deae1cc6bbe5ef5820224f72bb02565677e1ade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63226</th>\n",
       "      <td>905571</td>\n",
       "      <td>901480</td>\n",
       "      <td>vitrage</td>\n",
       "      <td>vitrage-tempest-plugin</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>28619</td>\n",
       "      <td>2024-01-15 09:22:15</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>28619</td>\n",
       "      <td>2023-11-20 18:56:15</td>\n",
       "      <td>905571.0</td>\n",
       "      <td>Ib49b025e75acddfbbdca4c5fd885f0dc615c4185</td>\n",
       "      <td>901480.0</td>\n",
       "      <td>Icdbe494f398420faa36cfcca3e50233b805ad45d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63227</th>\n",
       "      <td>913611</td>\n",
       "      <td>714728</td>\n",
       "      <td>charms.openstack</td>\n",
       "      <td>openstack-zuul-jobs</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>10058</td>\n",
       "      <td>2024-03-19 01:23:42</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>8556</td>\n",
       "      <td>2020-03-24 17:42:28</td>\n",
       "      <td>913611.0</td>\n",
       "      <td>Ib854bb24f9bba1cca8f6d4e201166d93ba4850af</td>\n",
       "      <td>714728.0</td>\n",
       "      <td>Ic17ec65b2229d46b799e0c41824e6e368723098b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63228</th>\n",
       "      <td>913612</td>\n",
       "      <td>714728</td>\n",
       "      <td>charms.openstack</td>\n",
       "      <td>openstack-zuul-jobs</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>10058</td>\n",
       "      <td>2024-03-19 01:28:23</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>8556</td>\n",
       "      <td>2020-03-24 17:42:28</td>\n",
       "      <td>913612.0</td>\n",
       "      <td>If1df5780a1e92e7d5b1c17b792ea74dcae2d15d0</td>\n",
       "      <td>714728.0</td>\n",
       "      <td>Ic17ec65b2229d46b799e0c41824e6e368723098b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63229</th>\n",
       "      <td>918978</td>\n",
       "      <td>918979</td>\n",
       "      <td>releases</td>\n",
       "      <td>openstack-ansible</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>28619</td>\n",
       "      <td>2024-05-10 08:50:33</td>\n",
       "      <td>MERGED</td>\n",
       "      <td>28619</td>\n",
       "      <td>2024-05-10 09:09:59</td>\n",
       "      <td>918978.0</td>\n",
       "      <td>I2ae212b34fb881dc2db5416a1769dcf7c262fffe</td>\n",
       "      <td>918979.0</td>\n",
       "      <td>I3cbf2f216817e80e62f8a61019f1d12f5b713d51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29085 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Source  Target       Source_repo             Target_repo Source_status  \\\n",
       "0       26005   26006    oslo-incubator              ceilometer        MERGED   \n",
       "1       66146   64831               pbr            requirements     ABANDONED   \n",
       "2       66453   71359           neutron                devstack        MERGED   \n",
       "3      153227   83150    project-config          oslo.messaging     ABANDONED   \n",
       "4      178352   86978    project-config                 grenade        MERGED   \n",
       "...       ...     ...               ...                     ...           ...   \n",
       "63225  903099  903095      requirements                  cinder        MERGED   \n",
       "63226  905571  901480           vitrage  vitrage-tempest-plugin        MERGED   \n",
       "63227  913611  714728  charms.openstack     openstack-zuul-jobs        MERGED   \n",
       "63228  913612  714728  charms.openstack     openstack-zuul-jobs        MERGED   \n",
       "63229  918978  918979          releases       openstack-ansible        MERGED   \n",
       "\n",
       "       owner_account_id_source       Source_created Target_status  \\\n",
       "0                            2  2013-04-03 15:23:05     ABANDONED   \n",
       "1                         2750  2014-01-12 00:41:12        MERGED   \n",
       "2                         1923  2014-01-13 22:48:28        MERGED   \n",
       "3                         8415  2015-02-05 13:29:18     ABANDONED   \n",
       "4                         6899  2015-04-28 19:24:44     ABANDONED   \n",
       "...                        ...                  ...           ...   \n",
       "63225                    13425  2023-12-07 18:02:36        MERGED   \n",
       "63226                    28619  2024-01-15 09:22:15        MERGED   \n",
       "63227                    10058  2024-03-19 01:23:42        MERGED   \n",
       "63228                    10058  2024-03-19 01:28:23        MERGED   \n",
       "63229                    28619  2024-05-10 08:50:33        MERGED   \n",
       "\n",
       "       owner_account_id_target       Target_created  number_source  \\\n",
       "0                            2  2013-04-03 15:23:50        26005.0   \n",
       "1                         2750  2014-01-03 13:58:35        66146.0   \n",
       "2                         1923  2014-02-05 19:48:53        66453.0   \n",
       "3                         6928  2014-03-26 18:01:12       153227.0   \n",
       "4                         4328  2014-04-11 17:54:33       178352.0   \n",
       "...                        ...                  ...            ...   \n",
       "63225                    13425  2023-12-07 16:47:22       903099.0   \n",
       "63226                    28619  2023-11-20 18:56:15       905571.0   \n",
       "63227                     8556  2020-03-24 17:42:28       913611.0   \n",
       "63228                     8556  2020-03-24 17:42:28       913612.0   \n",
       "63229                    28619  2024-05-10 09:09:59       918978.0   \n",
       "\n",
       "                                change_id_source  number_target  \\\n",
       "0      Ic01e0f16fe9e7634708fbb51499ccea3f4f40d63        26006.0   \n",
       "1      I01b2b7c78e7e7144280c98cdbbe29b012a8a8d93        64831.0   \n",
       "2      I92619a95bca2ae0c37e7fdd39da30119b43d1ad6        71359.0   \n",
       "3      I893f9a1c259157bc6e6829fe34067ede365c15b7        83150.0   \n",
       "4      I3e0f01221590f5e42f0c8fa659df62f83e0591af        86978.0   \n",
       "...                                          ...            ...   \n",
       "63225  I9027eac8bd5bf1efc9ef619d578b2e0d9450027f       903095.0   \n",
       "63226  Ib49b025e75acddfbbdca4c5fd885f0dc615c4185       901480.0   \n",
       "63227  Ib854bb24f9bba1cca8f6d4e201166d93ba4850af       714728.0   \n",
       "63228  If1df5780a1e92e7d5b1c17b792ea74dcae2d15d0       714728.0   \n",
       "63229  I2ae212b34fb881dc2db5416a1769dcf7c262fffe       918979.0   \n",
       "\n",
       "                                change_id_target  \n",
       "0      I2a3be7741e48b3b9fa5b0f182ddb25a0e46977ce  \n",
       "1      I7a22dbb47e85f3adf5d43583f5b9bac4f65fde14  \n",
       "2      I0958457355036fdab93156cd7fb4afd1a458918b  \n",
       "3      I9708322308655cbb4832fec1351ea1215e6e11ef  \n",
       "4      Id8f5875e1ae6a813808807571f511939ab4caf88  \n",
       "...                                          ...  \n",
       "63225  I3deae1cc6bbe5ef5820224f72bb02565677e1ade  \n",
       "63226  Icdbe494f398420faa36cfcca3e50233b805ad45d  \n",
       "63227  Ic17ec65b2229d46b799e0c41824e6e368723098b  \n",
       "63228  Ic17ec65b2229d46b799e0c41824e6e368723098b  \n",
       "63229  I3cbf2f216817e80e62f8a61019f1d12f5b713d51  \n",
       "\n",
       "[29085 rows x 14 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deps = pd.read_csv(\"./Files/source_target_evolution.csv\")\n",
    "# df_deps = pd.merge(\n",
    "#     left=df_deps,\n",
    "#     right=df[[\"number\", \"owner_account_id\", \"created\"]],\n",
    "#     left_on=['Source'],\n",
    "#     right_on=['number'],\n",
    "#     how='left',\n",
    "#     suffixes=('_target', '_source')\n",
    "# )\n",
    "# df_deps = pd.merge(\n",
    "#     left=df_deps,\n",
    "#     right=df[[\"number\", \"owner_account_id\", \"created\"]],\n",
    "#     left_on=['Target'],\n",
    "#     right_on=['number'],\n",
    "#     how='left',\n",
    "#     suffixes=('_source', '_target')\n",
    "# )\n",
    "# df_deps.rename(columns={\n",
    "#     \"status_source\": \"Source_status\",\n",
    "#     \"status_target\": \"Target_status\",\n",
    "#     \"author_source\": \"Source_author\",\n",
    "#     \"status_author\": \"Target_status\",\n",
    "#     \"created_source\": \"Source_created\",\n",
    "#     \"created_target\": \"Target_created\"}, inplace=True)\n",
    "df_deps.dropna(subset=[\"Source_status\", \"Target_status\"], inplace=True)\n",
    "# df_deps.drop(columns=[\"number_source\", \"number_target\"], inplace=True)\n",
    "# df_deps.to_csv(\"./Files/source_target_evolution.csv\", index=None)\n",
    "\n",
    "# 1. Number of dependencies a Target has (i.e., how many sources depend on this target)\n",
    "target_dependency_count = df_deps.groupby(\n",
    "    'Target')['Source'].nunique().reset_index()\n",
    "target_dependency_count.columns = ['Change', 'Num_Sources']\n",
    "\n",
    "# 2. Number of changes a Source is depended upon in Target (i.e., how many targets depend on this source)\n",
    "source_dependency_count = df_deps.groupby(\n",
    "    'Source')['Target'].nunique().reset_index()\n",
    "source_dependency_count.columns = ['Change', 'Num_Targets']\n",
    "\n",
    "# Combine both metrics into a single DataFrame\n",
    "dependency_summary = pd.merge(\n",
    "    target_dependency_count, source_dependency_count, on='Change', how='outer').fillna(0)\n",
    "dependency_summary[['Num_Sources', 'Num_Targets']] = dependency_summary[[\n",
    "    'Num_Sources', 'Num_Targets']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Num_Sources    76\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_summary.loc[dependency_summary[\"Num_Sources\"]>0, [\"Num_Sources\"]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_diff(row):\n",
    "    start, end = row['Source_date'], row['Target_date']\n",
    "    if start > end:\n",
    "        start, end = end, start\n",
    "    # current_date =  datetime.strptime(end, \"%Y-%m-%d %H:%M:%S\") \n",
    "    # previous_date = datetime.strptime(start, \"%Y-%m-%d %H:%M:%S\") \n",
    "    diff = end - start\n",
    "    diff = float(\"{:.2f}\".format(diff.total_seconds() / 3600))\n",
    "    return diff\n",
    "\n",
    "def lag_nbr_changes(row):\n",
    "    start, end = row['Source_date'], row['Target_date']\n",
    "    if start > end:\n",
    "        start, end = end, start\n",
    "    # end =  datetime.strptime(end, \"%Y-%m-%d %H:%M:%S\") \n",
    "    # start = datetime.strptime(start, \"%Y-%m-%d %H:%M:%S\") \n",
    "    res = df.loc[(df['created']>=start)&(df['created']<=end), \"number\"].nunique()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_identification['Source_date'] = pd.to_datetime(dependency_identification['Source_date'])\n",
    "dependency_identification['Target_date'] = pd.to_datetime(dependency_identification['Target_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_identification['lag'] = dependency_identification.apply(time_diff, axis=1)\n",
    "# dependency_identification['lag'] = dependency_identification.apply(time_diff, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lag = dependency_identification[['lag']]\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = np.abs((df_lag - df_lag.mean()) / df_lag.std())\n",
    "\n",
    "# Set a threshold for identifying outliers\n",
    "threshold = 3\n",
    "\n",
    "# Filter out the outliers\n",
    "dependency_identification = dependency_identification[(z_scores < threshold).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8570106554559637"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dependency_identification.loc[dependency_identification['lag']<=38*24, \"lag\"])/len(dependency_identification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6766.86"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_identification['lag'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37821"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dependency_identification)\n",
    "# len(dependency_identification[(dependency_identification['Source_status']!=\"NEW\") & (dependency_identification['Target']!=\"NEW\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49357"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(hpr.flatten_list(dependency_identification[['Source', 'Target']].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dependency_identification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdependency_identification\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeps_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dependency_identification' is not defined"
     ]
    }
   ],
   "source": [
    "dependency_identification['deps_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_identification['lag_changes'] = dependency_identification.apply(lag_nbr_changes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_identification.loc[dependency_identification['lag']==57, 'lag_changes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_identification.to_csv(\"./Files/source_target_evolution_clean.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When miss a dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_revi_deps = df_depends_on.loc[df_depends_on['when_identified']>1, 'Source'].unique()\n",
    "after_revi_need = df_needed_by.loc[(~df_needed_by['Target'].isin(after_revi_deps))&(df_needed_by['when_identified']>1), 'Target'].unique()\n",
    "after_review = set(after_revi_deps.tolist()+after_revi_deps.tolist())\n",
    "\n",
    "all_deps_deps_on = df_depends_on['Source'].unique()\n",
    "all_deps_need = df_needed_by.loc[(~df_needed_by['Target'].isin(all_deps_deps_on)), 'Target'].unique()\n",
    "all_dependent_changes = set(all_deps_deps_on.tolist()+all_deps_need.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_depends_ident = df_depends_on.loc[(df_depends_on['Source'].isin(after_revi_deps)), \"when_identified\"].tolist()\n",
    "df_needed_ident = df_needed_by.loc[(df_needed_by['Target'].isin(after_revi_need)), \"when_identified\"].tolist()\n",
    "ident_time = df_depends_ident + df_needed_ident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61672.0075"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(ident_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_depends_ident = df_depends_on.loc[(df_depends_on['worked_revisions']>1)&(df_depends_on['when_identified']>0)&(df_depends_on['Source'].isin(after_revi_deps)), \"when_identified\"].tolist()\n",
    "df_needed_ident = df_needed_by.loc[(df_needed_by['worked_revisions']>1)&(df_needed_by['when_identified']>0)&(df_needed_by['Target'].isin(after_revi_need)), \"when_identified\"].tolist()\n",
    "after_rev_ident_time = df_depends_ident + df_needed_ident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"time\": after_rev_ident_time}).to_csv(osp.join(\".\", \"Files\",\"Preliminary\", \"deps_ident.csv\"), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dependent_changes = pd.concat((df_depends_on, df_needed_by))\n",
    "all_dependent_changes.drop_duplicates(subset=['Source', 'Target'], inplace=True)\n",
    "all_dependent_changes = set(hpr.flatten_list(all_dependent_changes[['Source', 'Target']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45307284254107905"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['status']=='MERGED')&df['number'].isin(after_review)])/len(df[df['number'].isin(all_dependent_changes)&(df['status']=='MERGED')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_identification.loc[(dependency_identification['worked_revisions']>1)&(dependency_identification['worked_revisions']>1), \"when_identified\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_identification.to_csv(osp.join(\".\", \"Files\", \"Preliminary\", \"deps_ident.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_identification = pd.read_csv(osp.join(\".\", \"Files\", \"Preliminary\", \"deps_ident.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.7265162037037"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_identification.loc[dependency_identification['iden_type']=='slow', 'when_identified'].median()/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency_identification['when_identified'].median()\n",
    "dependency_identification.loc[(dependency_identification['Source_status']=='MERGED')&(dependency_identification['Target_status']=='MERGED')].to_csv(osp.join(\".\", \"Files\", \"Preliminary\", \"deps_ident.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many dependent changes contain a build failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependent_cha = pd.DataFrame({'number': list(all_dependent_changes)})\n",
    "df_dependent_cha = pd.merge(\n",
    "    df_dependent_cha,\n",
    "    right=df_build_fialure,\n",
    "    on='number'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5158020274299344"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dependent_cha[(df_dependent_cha['num_build_failures']>1)&df_dependent_cha['number'].isin(after_review)])/len(df_dependent_cha[(df_dependent_cha['num_build_failures']>1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_build_failure(nbr):\n",
    "    res = df.loc[df['number']==nbr, 'messages'].tolist()[0]\n",
    "    # print(res)\n",
    "    return type(res) == list\n",
    "\n",
    "def when_deps_linked(row):\n",
    "    link_date_deps = df_depends_on.loc[df_depends_on['Target']==row['number'], 'link_date'].tolist()\n",
    "    link_date_need = df_needed_by.loc[df_needed_by['Source']==row['number'], 'link_date'].tolist()\n",
    "    res = link_date_deps + link_date_need\n",
    "    res.sort()\n",
    "        \n",
    "    return res if len(res) > 0 else None\n",
    "\n",
    "def when_build_failure_occur(row):\n",
    "    linked_date = row['when_linked'][0]\n",
    "    messages = row['messages']\n",
    "    messages = sorted(messages, key=lambda d: d['date'])\n",
    "    build_fail_date = messages[0]['date'][:18]\n",
    "    print(linked_date, build_fail_date)\n",
    "    if linked_date == build_fail_date:\n",
    "        return 'Instant'\n",
    "    elif linked_date > build_fail_date:\n",
    "        return 'Before'\n",
    "    else:\n",
    "        return 'After'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependent_cha['has_build_failure'] = df_dependent_cha['number'].map(has_build_failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependent_cha = pd.merge(\n",
    "    left=df_dependent_cha, \n",
    "    right=df[['number', 'revisions', 'messages']], \n",
    "    left_on='number', \n",
    "    right_on='number', \n",
    "    how='inner',\n",
    "    suffixes=('_target', '_source')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependent_cha[\"revisions\"] = df_dependent_cha.loc[df_dependent_cha['when_linked'].notna(), \"revisions\"].map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6457274105788957"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dependent_cha[(df_dependent_cha['has_build_failure']==True)])/len(df_dependent_cha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependent_cha['when_linked'] = df_dependent_cha[df_dependent_cha['has_build_failure']==True].apply(when_deps_linked, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependent_cha['when_failure_occur'] = df_dependent_cha[df_dependent_cha['when_linked'].notna()].apply(when_build_failure_occur,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4076660988074957"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7179/len(df_dependent_cha.loc[df_dependent_cha['when_linked'].notna(), \"when_failure_occur\"])#.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the size of our testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(10):\n",
    "    test = pd.read_csv(f\"./Files/Data/Test/{i}.csv\")\n",
    "    result.append(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual_analysis = pd.DataFrame({'number': df_depends_on['Target'].unique().tolist() + df_needed_by['Source'].unique().tolist()})\n",
    "df_manual_analysis.drop_duplicates(subset='number', inplace=True)\n",
    "df_manual_analysis = df_manual_analysis.sample(n=379)\n",
    "df_manual_analysis.sort_values('number', inplace=True)\n",
    "df_manual_analysis.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_manual_analysis = pd.merge(\n",
    "    left=df_manual_analysis, \n",
    "    right=df_depends_on.drop_duplicates(subset='Target')[['Target', 'worked_revisions']], \n",
    "    left_on='number',\n",
    "    right_on='Target',\n",
    "    how='left',\n",
    "    suffixes=('_target', '_source')\n",
    ")\n",
    "df_manual_analysis.loc[df_manual_analysis['worked_revisions'].isnull(), 'worked_revisions'] = df_manual_analysis.loc[df_manual_analysis['worked_revisions'].isnull(), 'number'].map(lambda x: df_needed_by.loc[df_needed_by['Source']==x, 'worked_revisions'].values[0])\n",
    "labels = {\n",
    "    1: \"Configuration\",\n",
    "    2: \"Dependency\",\n",
    "    3: \"Code enhancement\",\n",
    "    4: \"New features\",\n",
    "    5: \"Docs\",\n",
    "    6: \"Renaming\",\n",
    "    7: \"Tests\",\n",
    "    8: \"Refactoring\",\n",
    "    9: \"Moving resources\",\n",
    "    10: \"Others\",\n",
    "}\n",
    "nbr = 920233\n",
    "df_manual_analysis.loc[\n",
    "    df_manual_analysis['number']==nbr,\n",
    "    [\"reviewer_suggest\", \"reason\", 'comment']\n",
    "] = [0, labels[2], \"\"]\n",
    "df_manual_analysis.to_csv(osp.join(\".\", \"Files\", \"manual_analysis.csv\"), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual_analysis = pd.read_csv(osp.join(\".\", \"Files\", \"manual_analysis.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>worked_revisions</th>\n",
       "      <th>reason</th>\n",
       "      <th>comment</th>\n",
       "      <th>reviewer_suggest</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Refactoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Code enhancement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Code enhancement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Configuration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>918920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>919265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>919339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>919494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>920233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dependency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number  worked_revisions            reason comment  reviewer_suggest  tag\n",
       "0    156691               1.0       Refactoring     NaN               0.0  NaN\n",
       "1    161355               1.0  Code enhancement     NaN               0.0  NaN\n",
       "2    175394               1.0  Code enhancement     NaN               0.0  NaN\n",
       "3    181260               1.0             Tests     NaN               0.0  NaN\n",
       "4    182072               1.0     Configuration     NaN               0.0  NaN\n",
       "..      ...               ...               ...     ...               ...  ...\n",
       "374  918920               1.0             Tests     NaN               0.0  NaN\n",
       "375  919265               1.0             Tests     NaN               0.0  NaN\n",
       "376  919339               1.0             Tests     NaN               0.0  NaN\n",
       "377  919494               1.0             Tests     NaN               0.0  NaN\n",
       "378  920233               1.0        Dependency     NaN               0.0  NaN\n",
       "\n",
       "[387 rows x 6 columns]"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manual_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual_analysis = pd.read_csv(osp.join(\".\", \"Files\", \"manual_analysis.csv\"))\n",
    "df_manual_analysis.loc[df_manual_analysis['reason']=='Test', 'reason'] = 'Tests'\n",
    "df_manual_analysis['reason'] = df_manual_analysis['reason'].map(lambda x: x.split(','))\n",
    "df_manual_analysis = df_manual_analysis.explode(column='reason')\n",
    "# Calculate the percentage of missing dependencies\n",
    "# df_manual_analysis = df_manual_analysis.groupby('reason').apply(lambda x: pd.Series({\n",
    "#     '\\# missing deps': (x['worked_revisions'] > 1).sum(),\n",
    "#     'Total': x['worked_revisions'].count(),\n",
    "#     '\\\\% of missing': f\"{round((x['worked_revisions'] > 1).sum() / len(x) * 100, 2)}\\%\"\n",
    "#     # 'Description': 'No description yet'\n",
    "# })).reset_index()\n",
    "\n",
    "# # # Rename columns to match the desired output\n",
    "# df_manual_analysis.rename(columns={'reason': 'Category'}, inplace=True)\n",
    "# df_manual_analysis.sort_values(by='\\# missing deps', ascending=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\n",
    "    1: 'Complex change',\n",
    "    2: 'Project unfamiliarity',\n",
    "    3: 'Inconsistent deps',\n",
    "    4: 'Build failure'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{A detailed overview of various reasons for which developers miss adding a dependency.}\n",
      "\\label{tab:manual-analysis}\n",
      "\\begin{tabular}{lrrl}\n",
      "\\toprule\n",
      "Category & \\# missing deps & Total & \\% of missing \\\\\n",
      "\\midrule\n",
      "Configuration & 43 & 110 & 39.09\\% \\\\\n",
      "Dependency & 28 & 55 & 50.91\\% \\\\\n",
      "Refactoring & 26 & 60 & 43.33\\% \\\\\n",
      "New features & 25 & 48 & 52.08\\% \\\\\n",
      "Tests & 23 & 52 & 44.23\\% \\\\\n",
      "Code enhancement & 14 & 26 & 53.85\\% \\\\\n",
      "Docs & 8 & 13 & 61.54\\% \\\\\n",
      "Moving resources & 3 & 11 & 27.27\\% \\\\\n",
      "Renaming & 2 & 11 & 18.18\\% \\\\\n",
      "Duplicate & 0 & 1 & 0.0\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_manual_analysis.to_latex(index=False, caption='A detailed overview of various reasons for which developers miss adding a dependency.', label='tab:manual-analysis', float_format=\"%.2f\", ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
